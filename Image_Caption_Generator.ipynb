{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "_y_Pv0Rwt5YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the pre-trained InceptionV3 model"
      ],
      "metadata": {
        "id": "zwppZNuguKP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model = tf.keras.applications.InceptionV3(include_top=True, weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABTbPg_euBb2",
        "outputId": "12f651ef-ee85-4a30-8055-5448c31ec20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96112376/96112376 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the tokenizer"
      ],
      "metadata": {
        "id": "v_7l-37_uTJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer_path = 'tokenizer.pkl'\n",
        "tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(tokenizer_path)"
      ],
      "metadata": {
        "id": "4eQaa22euaCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the maximum sequence length (number of words) for captions"
      ],
      "metadata": {
        "id": "sEmMzmpWu0R2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 20"
      ],
      "metadata": {
        "id": "A-_XaaUSu5a5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the pre-trained caption generation model"
      ],
      "metadata": {
        "id": "gpzKF5uuu-RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'caption_generator_model.h5'\n",
        "model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "2nez-FZzvAht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the word-to-index and index-to-word mappings"
      ],
      "metadata": {
        "id": "tTT3wSBnvSaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = tokenizer.word_index\n",
        "index_to_word = {index: word for word, index in word_to_index.items()}"
      ],
      "metadata": {
        "id": "KRD4zMvBvV78"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model = tf.keras.applications.InceptionV3(include_top=True, weights='imagenet')\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Preprocess the image for input to the InceptionV3 model.\"\"\"\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((299, 299))\n",
        "    img = np.array(img)\n",
        "    img = img / 255.0\n",
        "    img = img.reshape(1, 299, 299, 3)\n",
        "    return img\n",
        "\n",
        "def generate_caption(image_path):\n",
        "    \"\"\"Generate a caption for the given image.\"\"\"\n",
        "    img = preprocess_image(image_path)\n",
        "    features = inception_model.predict(img)\n",
        "    features = features.reshape(1, -1)\n",
        "\n",
        "    start_token = tokenizer.word_index['<start>']\n",
        "    end_token = tokenizer.word_index['<end>']\n",
        "\n",
        "    caption = []\n",
        "    input_sequence = [start_token]\n",
        "    for _ in range(max_sequence_length):\n",
        "        sequence = np.array(input_sequence)\n",
        "        y_pred = model.predict([features, sequence])\n",
        "        y_pred = np.argmax(y_pred)\n",
        "\n",
        "        if index_to_word[y_pred] == '<end>':\n",
        "            break\n",
        "\n",
        "        caption.append(index_to_word[y_pred])\n",
        "        input_sequence.append(y_pred)\n",
        "\n",
        "    generated_caption = ' '.join(caption)\n",
        "    return generated_caption\n"
      ],
      "metadata": {
        "id": "Nw7XgXdMvnrS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Path to the image for caption generation"
      ],
      "metadata": {
        "id": "k3CC-yHFvsmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = 'example_image.jpg'"
      ],
      "metadata": {
        "id": "gBalMV2pvsFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate caption for the image"
      ],
      "metadata": {
        "id": "vecU8jZBvzSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "caption = generate_caption(image_path)\n",
        "print('Generated Caption:', caption)"
      ],
      "metadata": {
        "id": "0dytxQzAv2np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the image"
      ],
      "metadata": {
        "id": "BWCd-UJWv57L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(image_path)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "13RZrM4Cv888"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}